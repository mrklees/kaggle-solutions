{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Bayesian Approach to the Titanic Data Set\n",
    "\n",
    "A recent obsession of mine has been Bayesian Neural Networks.  We will apply this approach in two ways. First in a pure NN solution which utilizes dropout.  Second, we'll use edward to express our uncertainty over the weights and sample from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# core python\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "# Data Structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prediction\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from edward.models import Normal\n",
    "np.random.seed(606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions encompass a data cleaning pipeline. The function preproc at the end wraps the rest so that a single function call will return the desired data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports data and splits Data into training and test sets\n",
    "def split_and_clean():\n",
    "    X, y = select_features(pd.read_csv('train.csv'))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 606, stratify = y)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Select the features of interest. \n",
    "def select_features(data):\n",
    "    target = ['Survived']\n",
    "    features = ['Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
    "    dropped_features = ['Cabin', 'Ticket']\n",
    "    X = data[features].drop(dropped_features, axis=1)\n",
    "    y = data[target]\n",
    "    return X, y\n",
    "\n",
    "# Fill na's with the mean (in the case of fare), and with C in the case of embarked.\n",
    "def fix_na(data):\n",
    "    na_vars = {\"Fare\" : data.Fare.mean(), \"Embarked\" : \"C\"}\n",
    "    return data.fillna(na_vars)\n",
    "\n",
    "# Processes categorical data into dummy vars\n",
    "def create_dummies(data, cat_vars, cat_types):\n",
    "    cat_data = data[cat_vars].values\n",
    "    for i in range(len(cat_vars)):   \n",
    "        bins = LabelBinarizer().fit_transform(cat_data[:, 0].astype(cat_types[i]))\n",
    "        cat_data = np.delete(cat_data, 0, axis=1)\n",
    "        cat_data = np.column_stack((cat_data, bins))\n",
    "    return cat_data\n",
    "\n",
    "# Processes numeric data \n",
    "def standardize(data, real_vars):\n",
    "    real_data = data[real_vars]\n",
    "    scale = StandardScaler()\n",
    "    return scale.fit_transform(real_data)\n",
    "\n",
    "# Extract titles from the Name field and create appropriate One Hot Encoded Columns\n",
    "def extract_titles(data):\n",
    "    title_array = data.Name\n",
    "    first_names = title_array.str.rsplit(', ', expand=True, n=1)\n",
    "    titles = first_names[1].str.rsplit('.', expand=True, n=1)\n",
    "    known_titles = ['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
    "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
    "       'Jonkheer']\n",
    "    for title in known_titles:\n",
    "        try:\n",
    "            titles[title] = titles[0].str.contains(title).astype('int')\n",
    "        except:\n",
    "            titles[title] = 0\n",
    "    return titles.drop([0,1], axis=1).values\n",
    "\n",
    "# Multilayer Perceptron for filling in ages\n",
    "def age_model(features=27, n_layers=15, n_hidden = 256, dropout = 0.25, optimizer=Adam()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_hidden, input_shape=(features, ), activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dropout(dropout))    \n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(n_hidden, activation='relu'))\n",
    "        model.add(Dropout(dropout))           \n",
    "    model.add(Dense(1))   \n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train the age model and fill in those missing values in the dataset\n",
    "def impute_ages(data):\n",
    "    known = data[np.isnan(data[:, -1].astype('float'))==False]\n",
    "    unknown = data[np.isnan(data[:, -1].astype('float'))]\n",
    "    y = known[:, -1]\n",
    "    X = known[:, :-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 606)\n",
    "    model = age_model()\n",
    "    model.fit(X_train, y_train, batch_size=64, epochs = 50,\n",
    "              verbose = 0, validation_split = 0.2)\n",
    "    ages_predicted = model.predict(unknown[:, :-1])\n",
    "    data[np.isnan(data[:, -1].astype('float'))] = ages_predicted\n",
    "    return data\n",
    "\n",
    "# Executes the full preprocessing pipeline.\n",
    "def preproc():\n",
    "    # Import Data & Split\n",
    "    X_train_, y_train, X_test_, y_test = split_and_clean()\n",
    "    # Fill NAs\n",
    "    X_train, X_test = fix_na(X_train_), fix_na(X_test_)\n",
    "    # Preproc Categorical Vars\n",
    "    cat_vars = ['Pclass', 'Sex', 'Embarked']\n",
    "    cat_types = ['int', 'str', 'str']\n",
    "    X_train_cat, X_test_cat = create_dummies(X_train, cat_vars, cat_types), create_dummies(X_test, cat_vars, cat_types)\n",
    "    # Preprocess Numeric Vars\n",
    "    real_vars = ['Fare', 'SibSp', 'Parch']\n",
    "    X_train_real, X_test_real = standardize(X_train, real_vars), standardize(X_test, real_vars)\n",
    "    # Extract Titles\n",
    "    X_train_titles, X_test_titles = extract_titles(X_train), extract_titles(X_test)\n",
    "    # Recombine\n",
    "    X_train, X_test = np.column_stack((X_train_cat, X_train_real, X_train_titles, X_train_.Age)), np.column_stack((X_test_cat, X_test_real, X_test_titles, X_test.Age))\n",
    "    # Fill Missing Ages\n",
    "    X_train, X_test = impute_ages(X_train), impute_ages(X_test)\n",
    "    return X_train, np_utils.to_categorical(y_train.values), X_test, np_utils.to_categorical(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the preproc pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = preproc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a Keras model.  At the top we define a series of variables that we'll use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(features=28, n_layers=10, n_hidden = 64, dropout = 0.3, optimizer=Adam()):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_hidden, input_shape=(features, ), activation='relu', kernel_initializer='random_normal'))\n",
    "    model.add(Dropout(dropout))    \n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(n_hidden, activation='relu'))\n",
    "        model.add(Dropout(dropout))           \n",
    "    model.add(Dense(2, activation='softmax'))   \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The last thing to do is to compile and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_model(n_layers=14, n_hidden=64, dropout=0.3, epochs=200):\n",
    "    model = create_model(features=X_train.shape[1], n_layers=n_layers, n_hidden=n_hidden, dropout=dropout)\n",
    "    model.fit(X_train, y_train , epochs=epochs, batch_size = 64)\n",
    "    return model\n",
    "\n",
    "param_grid = {\n",
    "    'n_layers' : [5, 10],\n",
    "    'n_hidden' : [25, 75],\n",
    "    'dropout'  : [0.25, 0.35]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "445/445 [==============================] - 0s - loss: 0.6903 - acc: 0.5865      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6734 - acc: 0.6292     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6555 - acc: 0.6315     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.6310 - acc: 0.6315     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.6073 - acc: 0.6315     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5923 - acc: 0.6315     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5906 - acc: 0.6315     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5668 - acc: 0.6315     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5662 - acc: 0.6315     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5364 - acc: 0.6337     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 0s - loss: 0.6892 - acc: 0.5843     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6779 - acc: 0.5820     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6716 - acc: 0.5865     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.6519 - acc: 0.5865     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.6155 - acc: 0.5910     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.6192 - acc: 0.6112     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5723 - acc: 0.7371     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - ETA: 0s - loss: 0.5158 - acc: 0.906 - 0s - loss: 0.5598 - acc: 0.7708     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5171 - acc: 0.7708     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5161 - acc: 0.7775     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 0s - loss: 0.6847 - acc: 0.5942      \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.6455 - acc: 0.6323     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.6038 - acc: 0.6323     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.5547 - acc: 0.6323     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.5268 - acc: 0.6435     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.5221 - acc: 0.7556     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.4843 - acc: 0.8274     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.4831 - acc: 0.8251     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.4736 - acc: 0.8027     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4553 - acc: 0.8341     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 0s - loss: 0.6752 - acc: 0.6292      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6587 - acc: 0.6315     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6347 - acc: 0.6315     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5733 - acc: 0.6315     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.5541 - acc: 0.6315     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5614 - acc: 0.7303     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5991 - acc: 0.7775     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5678 - acc: 0.7258     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5389 - acc: 0.7978     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5367 - acc: 0.8157     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 0s - loss: 0.6853 - acc: 0.5708      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6653 - acc: 0.5865     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6485 - acc: 0.5865     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.6040 - acc: 0.5865     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.5692 - acc: 0.7483     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5405 - acc: 0.7843     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5601 - acc: 0.7640     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5641 - acc: 0.7708     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5619 - acc: 0.7753     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5630 - acc: 0.7528     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 1s - loss: 0.6688 - acc: 0.6188      \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.6460 - acc: 0.6345     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.6018 - acc: 0.6323     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.5846 - acc: 0.6457     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.5576 - acc: 0.7422     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.5186 - acc: 0.7623     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.5278 - acc: 0.7915     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.5251 - acc: 0.7825     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.5795 - acc: 0.7937     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4717 - acc: 0.8206     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 0s - loss: 0.6426 - acc: 0.6202      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.5609 - acc: 0.7483     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.5336 - acc: 0.7798     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.4329 - acc: 0.8337     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.4409 - acc: 0.8292     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.4244 - acc: 0.8404     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.4042 - acc: 0.8517     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.4165 - acc: 0.8382     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.3905 - acc: 0.8472     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.3824 - acc: 0.8539     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6741 - acc: 0.5843      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6052 - acc: 0.7169     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.5319 - acc: 0.7798     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.4891 - acc: 0.8112     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.4523 - acc: 0.8225     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.4285 - acc: 0.8292     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.4425 - acc: 0.8270     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.4221 - acc: 0.8315     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.4237 - acc: 0.8225     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.4114 - acc: 0.8360     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 0s - loss: 0.6323 - acc: 0.6188      \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.5103 - acc: 0.7623     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.4326 - acc: 0.8229     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.4264 - acc: 0.8184     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.4087 - acc: 0.8206     \n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 0s - loss: 0.3892 - acc: 0.8498     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.4094 - acc: 0.8520     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.3753 - acc: 0.8475     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.3834 - acc: 0.8408     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.3586 - acc: 0.8475     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6688 - acc: 0.6202     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6120 - acc: 0.6584     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.5453 - acc: 0.7528     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5400 - acc: 0.8045     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.4879 - acc: 0.8022     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.4910 - acc: 0.8022     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5002 - acc: 0.8180     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.4685 - acc: 0.8292     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.4234 - acc: 0.8360     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.4197 - acc: 0.8494     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6834 - acc: 0.5978     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6552 - acc: 0.6202     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6443 - acc: 0.6090     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5367 - acc: 0.7888     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.4944 - acc: 0.7910     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5243 - acc: 0.8180     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5227 - acc: 0.7798     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5466 - acc: 0.7955     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5220 - acc: 0.7910     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.4952 - acc: 0.8000     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 1s - loss: 0.6612 - acc: 0.6323     \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.6452 - acc: 0.6323     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.5418 - acc: 0.7040     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.4899 - acc: 0.8139     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.4979 - acc: 0.8274     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.4822 - acc: 0.8251     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.4705 - acc: 0.8318     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.4357 - acc: 0.8386     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.4601 - acc: 0.8341     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4066 - acc: 0.8430     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6627 - acc: 0.6045      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6382 - acc: 0.6292     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6070 - acc: 0.6315     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5817 - acc: 0.6315     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.5773 - acc: 0.7213     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5979 - acc: 0.7753     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5468 - acc: 0.7910     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5509 - acc: 0.7955     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5670 - acc: 0.8247     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5378 - acc: 0.8202     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6884 - acc: 0.5551      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6757 - acc: 0.5775     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6658 - acc: 0.5888     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.6401 - acc: 0.5820     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.6055 - acc: 0.6045     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.6031 - acc: 0.6921     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5649 - acc: 0.7461     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5677 - acc: 0.7551     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5472 - acc: 0.7843     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5400 - acc: 0.7730     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 1s - loss: 0.6893 - acc: 0.5561      \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.6531 - acc: 0.6502     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.6283 - acc: 0.6839     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.5392 - acc: 0.7511     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.5245 - acc: 0.7713     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.5056 - acc: 0.7668     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.4804 - acc: 0.7758     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.4527 - acc: 0.8206     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.4601 - acc: 0.8004     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4205 - acc: 0.8206     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6661 - acc: 0.6225      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6482 - acc: 0.6315     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6272 - acc: 0.6337     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.6150 - acc: 0.6315     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.5973 - acc: 0.6315     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5943 - acc: 0.6292     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5804 - acc: 0.7573     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5605 - acc: 0.7438     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5727 - acc: 0.7933     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5959 - acc: 0.7798     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6850 - acc: 0.5640     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6817 - acc: 0.5775     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6770 - acc: 0.5843     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.6717 - acc: 0.5798     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.6555 - acc: 0.5843     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.6311 - acc: 0.5843     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.6175 - acc: 0.5978     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.6531 - acc: 0.5978     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.6303 - acc: 0.7146     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.6019 - acc: 0.7438     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 2s - loss: 0.6798 - acc: 0.6031      \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.6520 - acc: 0.6300     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.6309 - acc: 0.6278     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.5925 - acc: 0.6323     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.5566 - acc: 0.6480     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.5555 - acc: 0.7466     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.5352 - acc: 0.7377     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.5234 - acc: 0.7332     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.5171 - acc: 0.7803     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4983 - acc: 0.7758     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6671 - acc: 0.6090     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6018 - acc: 0.6247     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.5534 - acc: 0.7416     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5568 - acc: 0.7685     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.4777 - acc: 0.8067     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.4931 - acc: 0.8247     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.4774 - acc: 0.8135     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.4493 - acc: 0.8360     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.4246 - acc: 0.8292     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.4280 - acc: 0.8315     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 1s - loss: 0.6766 - acc: 0.5820      \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6164 - acc: 0.6697     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.5574 - acc: 0.7708     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5222 - acc: 0.7685     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.4790 - acc: 0.7888     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.4850 - acc: 0.8045     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.4697 - acc: 0.8067     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.4868 - acc: 0.7888     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.4376 - acc: 0.8247     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.4807 - acc: 0.8135     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 1s - loss: 0.6596 - acc: 0.6099     \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.5760 - acc: 0.6390     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.5125 - acc: 0.7982     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.4783 - acc: 0.8161     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.4404 - acc: 0.8229     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.4680 - acc: 0.8206     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.4126 - acc: 0.8161     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.4032 - acc: 0.8206     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.4033 - acc: 0.8117     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4010 - acc: 0.8161     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 3s - loss: 0.6763 - acc: 0.6090     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.6825 - acc: 0.6225     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6125 - acc: 0.6315     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5894 - acc: 0.6315     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.5835 - acc: 0.7258     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.5695 - acc: 0.7820     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5071 - acc: 0.8090     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.5264 - acc: 0.8022     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.4992 - acc: 0.8157     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5414 - acc: 0.8202     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "445/445 [==============================] - 2s - loss: 0.6685 - acc: 0.5596     \n",
      "Epoch 2/10\n",
      "445/445 [==============================] - 0s - loss: 0.5795 - acc: 0.7213     \n",
      "Epoch 3/10\n",
      "445/445 [==============================] - 0s - loss: 0.6477 - acc: 0.7169     \n",
      "Epoch 4/10\n",
      "445/445 [==============================] - 0s - loss: 0.5521 - acc: 0.7596     \n",
      "Epoch 5/10\n",
      "445/445 [==============================] - 0s - loss: 0.5827 - acc: 0.7708     \n",
      "Epoch 6/10\n",
      "445/445 [==============================] - 0s - loss: 0.6152 - acc: 0.7303     \n",
      "Epoch 7/10\n",
      "445/445 [==============================] - 0s - loss: 0.5473 - acc: 0.7753     \n",
      "Epoch 8/10\n",
      "445/445 [==============================] - 0s - loss: 0.4890 - acc: 0.8180     \n",
      "Epoch 9/10\n",
      "445/445 [==============================] - 0s - loss: 0.5046 - acc: 0.8067     \n",
      "Epoch 10/10\n",
      "445/445 [==============================] - 0s - loss: 0.5150 - acc: 0.8090     \n",
      " 32/445 [=>............................] - ETA: 0sEpoch 1/10\n",
      "446/446 [==============================] - 2s - loss: 0.6587 - acc: 0.6099     \n",
      "Epoch 2/10\n",
      "446/446 [==============================] - 0s - loss: 0.5446 - acc: 0.6861     \n",
      "Epoch 3/10\n",
      "446/446 [==============================] - 0s - loss: 0.5667 - acc: 0.7960     \n",
      "Epoch 4/10\n",
      "446/446 [==============================] - 0s - loss: 0.5535 - acc: 0.7646     \n",
      "Epoch 5/10\n",
      "446/446 [==============================] - 0s - loss: 0.4675 - acc: 0.8274     \n",
      "Epoch 6/10\n",
      "446/446 [==============================] - 0s - loss: 0.4688 - acc: 0.8184     \n",
      "Epoch 7/10\n",
      "446/446 [==============================] - 0s - loss: 0.4972 - acc: 0.8318     \n",
      "Epoch 8/10\n",
      "446/446 [==============================] - 0s - loss: 0.4764 - acc: 0.8094     \n",
      "Epoch 9/10\n",
      "446/446 [==============================] - 0s - loss: 0.4689 - acc: 0.8049     \n",
      "Epoch 10/10\n",
      "446/446 [==============================] - 0s - loss: 0.4605 - acc: 0.8094     \n",
      " 32/446 [=>............................] - ETA: 0sEpoch 1/10\n",
      "668/668 [==============================] - 2s - loss: 0.6271 - acc: 0.6632     \n",
      "Epoch 2/10\n",
      "668/668 [==============================] - 0s - loss: 0.4981 - acc: 0.7934     \n",
      "Epoch 3/10\n",
      "668/668 [==============================] - 0s - loss: 0.4675 - acc: 0.8054     \n",
      "Epoch 4/10\n",
      "668/668 [==============================] - 0s - loss: 0.4176 - acc: 0.8308     \n",
      "Epoch 5/10\n",
      "668/668 [==============================] - 0s - loss: 0.4242 - acc: 0.8144     \n",
      "Epoch 6/10\n",
      "668/668 [==============================] - 0s - loss: 0.4247 - acc: 0.8338     \n",
      "Epoch 7/10\n",
      "668/668 [==============================] - 0s - loss: 0.4162 - acc: 0.8533     \n",
      "Epoch 8/10\n",
      "668/668 [==============================] - 0s - loss: 0.4016 - acc: 0.8578     \n",
      "Epoch 9/10\n",
      "668/668 [==============================] - 0s - loss: 0.3992 - acc: 0.8488     \n",
      "Epoch 10/10\n",
      "668/668 [==============================] - 0s - loss: 0.4004 - acc: 0.8413     \n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_.model\n",
    "train_score, train_accuracy = best_model.evaluate(X_train, y_train)\n",
    "test_score, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print('Training Score: {0}, Trainng Accuracy: {1}'.format(train_score, train_accuracy))\n",
    "print('Test Score: {0}, Test Accuracy: {1}'.format(test_score, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid_result.best_params_)\n",
    "plt.hist(grid_result.cv_results_['mean_train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      22.0\n",
       "1      38.0\n",
       "2      26.0\n",
       "3      35.0\n",
       "4      35.0\n",
       "6      54.0\n",
       "7       2.0\n",
       "8      27.0\n",
       "9      14.0\n",
       "10      4.0\n",
       "11     58.0\n",
       "12     20.0\n",
       "13     39.0\n",
       "14     14.0\n",
       "15     55.0\n",
       "16      2.0\n",
       "18     31.0\n",
       "20     35.0\n",
       "21     34.0\n",
       "22     15.0\n",
       "23     28.0\n",
       "24      8.0\n",
       "25     38.0\n",
       "27     19.0\n",
       "30     40.0\n",
       "33     66.0\n",
       "34     28.0\n",
       "35     42.0\n",
       "37     21.0\n",
       "38     18.0\n",
       "       ... \n",
       "856    45.0\n",
       "857    51.0\n",
       "858    24.0\n",
       "860    41.0\n",
       "861    21.0\n",
       "862    48.0\n",
       "864    24.0\n",
       "865    42.0\n",
       "866    27.0\n",
       "867    31.0\n",
       "869     4.0\n",
       "870    26.0\n",
       "871    47.0\n",
       "872    33.0\n",
       "873    47.0\n",
       "874    28.0\n",
       "875    15.0\n",
       "876    20.0\n",
       "877    19.0\n",
       "879    56.0\n",
       "880    25.0\n",
       "881    33.0\n",
       "882    22.0\n",
       "883    28.0\n",
       "884    25.0\n",
       "885    39.0\n",
       "886    27.0\n",
       "887    19.0\n",
       "889    26.0\n",
       "890    32.0\n",
       "Name: Age, Length: 714, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_data = pd.read_csv('train.csv')\n",
    "age_unknown = age_data[age_data.isnull()]\n",
    "age_known = age_data[age_data.isnull() == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_testing():\n",
    "    X = pd.read_csv('test.csv')\n",
    "    # Fill NAs\n",
    "    X = fix_na(X)\n",
    "    # Preproc Categorical Vars\n",
    "    cat_vars = ['Pclass', 'Sex', 'Embarked']\n",
    "    cat_types = ['int', 'str', 'str']\n",
    "    X_cat = create_dummies(X, cat_vars, cat_types)\n",
    "    # Preprocess Numeric Vars\n",
    "    real_vars = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "    X_real = standardize(X, real_vars) \n",
    "    # Extract Titles\n",
    "    X_titles = extract_titles(X)\n",
    "    # Recombine\n",
    "    X = np.column_stack((X_cat, X_real, X_titles))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = preproc_testing()\n",
    "prediction = grid_result.predict(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['PassengerId'] = pd.read_csv('test.csv').PassengerId\n",
    "submission['Survived'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('keras_titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
